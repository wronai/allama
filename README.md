![allama-logo.svg](allama-logo.svg)

# TestLLM - System Testowania Modeli LLM ğŸ§ª

Kompleksowy system do testowania i porÃ³wnywania modeli Large Language Models (LLM) w kontekÅ›cie generowania kodu Python. Projekt umoÅ¼liwia automatycznÄ… ocenÄ™ jakoÅ›ci wygenerowanego kodu poprzez rÃ³Å¼ne metryki i generuje szczegÃ³Å‚owe raporty HTML.

## âœ¨ FunkcjonalnoÅ›ci

- **Automatyczne testowanie** multiple modeli LLM z konfigurowalnymi promptami
- **Ocena jakoÅ›ci kodu** - sprawdzanie skÅ‚adni, wykonalnoÅ›ci, stylu i funkcjonalnoÅ›ci
- **SzczegÃ³Å‚owe raporty HTML** z metrykami, wykresami i porÃ³wnaniami
- **Eksport wynikÃ³w** do CSV i JSON dla dalszej analizy
- **KonfigurowalnoÅ›Ä‡** - Å‚atwe dodawanie nowych modeli i testÃ³w
- **Wsparcie dla rÃ³Å¼nych API** - Ollama, lokalnych serwerÃ³w, usÅ‚ug w chmurze
- **Ranking modeli** na podstawie wydajnoÅ›ci i jakoÅ›ci

## ğŸš€ Szybki Start

### 1. Instalacja

```bash
# Sklonuj projekt
git clone https://github.com/wronai/allama.git
cd testllm

# Zainstaluj zaleÅ¼noÅ›ci
pip install -r requirements.txt

# Lub uÅ¼yj skryptu setup
python setup.py
```

### 2. Konfiguracja modeli

Edytuj plik `models.csv` aby skonfigurowaÄ‡ swoje modele:

```csv
model_name,url,auth_header,auth_value,think,description
deepseek-coder:1.3b,http://192.168.188.108:8081/api/chat,,,false,DeepSeek Coder na lokalnym serwerze
mistral:latest,http://192.168.188.212:11434/api/chat,,,false,Mistral Latest na Ollama
gpt-4,https://api.openai.com/v1/chat/completions,Authorization,Bearer sk-...,false,OpenAI GPT-4
```

**Kolumny w CSV:**
- `model_name` - nazwa modelu
- `url` - endpoint API
- `auth_header` - nagÅ‚Ã³wek autoryzacji (opcjonalny)
- `auth_value` - wartoÅ›Ä‡ autoryzacji (opcjonalny)
- `think` - czy model obsÅ‚uguje parametr "think" (true/false)
- `description` - opis modelu

### 3. Uruchomienie testÃ³w

```bash
# Podstawowe testy wszystkich modeli
python main.py

# Zaawansowane opcje
python test_runner.py --benchmark

# Test pojedynczego modelu
python test_runner.py --single-model "deepseek-coder:1.3b"

# PorÃ³wnanie okreÅ›lonych modeli
python test_runner.py --compare "mistral:latest" "deepseek-coder:1.3b"
```

## ğŸ“Š Metryki Oceny

System ocenia wygenerowany kod wedÅ‚ug nastÄ™pujÄ…cych kryteriÃ³w:

### Podstawowe metryki (automatyczne)
- âœ… **SkÅ‚adnia poprawna** - czy kod kompiluje siÄ™ bez bÅ‚Ä™dÃ³w
- âœ… **WykonalnoÅ›Ä‡** - czy kod uruchamia siÄ™ bez bÅ‚Ä™dÃ³w runtime
- âœ… **SÅ‚owa kluczowe** - czy kod zawiera oczekiwane elementy z promptu

### Metryki jakoÅ›ci kodu
- ğŸ“ **Definicje funkcji/klas** - poprawna struktura kodu
- ğŸ›¡ï¸ **ObsÅ‚uga bÅ‚Ä™dÃ³w** - try/catch, walidacja inputÃ³w
- ğŸ“š **Dokumentacja** - docstringi, komentarze
- ğŸ“¦ **Importy** - wÅ‚aÅ›ciwe uÅ¼ycie bibliotek
- ğŸ“ **DÅ‚ugoÅ›Ä‡ kodu** - rozsÄ…dna iloÅ›Ä‡ linii

### System punktowy
- SkÅ‚adnia poprawna: **3 punkty**
- Wykonuje siÄ™ bez bÅ‚Ä™dÃ³w: **2 punkty**  
- Zawiera oczekiwane elementy: **2 punkty**
- Ma definicje funkcji/klas: **1 punkt**
- Ma obsÅ‚ugÄ™ bÅ‚Ä™dÃ³w: **1 punkt**
- Ma dokumentacjÄ™: **1 punkt**
- **Maksymalnie: 10 punktÃ³w**

## ğŸ”§ Konfiguracja

### Dostosowanie promptÃ³w

Edytuj plik `config.py` aby zmieniÄ‡ prompty testowe:

```python
TEST_PROMPTS = [
    {
        "name": "Custom Function",
        "prompt": "Write a Python function that...",
        "expected_keywords": ["def", "function_name"],
        "expected_behavior": "function_definition"
    }
]
```

### WÅ‚asna konfiguracja JSON

# Test wszystkich modeli Ollama na lokalnym serwerze
python test_runner.py --models ollama_models.csv

# PorÃ³wnanie tylko modeli kodujÄ…cych
python test_runner.py --compare "deepseek-coder:1.3b" "codellama:7b" --output coding_models_comparison.html

# Szybki test pojedynczego modelu z jednym promptem
python test_runner.py --single-model "mistral:latest" --prompt-index 0 --output quick_test.html
```

## ğŸ”Œ Integracja z RÃ³Å¼nymi API

### Ollama (lokalny)
```csv
llama3.2:3b,http://localhost:11434/api/chat,,,false,Llama 3.2
```

### OpenAI API
```csv
gpt-4,https://api.openai.com/v1/chat/completions,Authorization,Bearer sk-your-key,false,OpenAI GPT-4
```

### Anthropic Claude
```csv
claude-3,https://api.anthropic.com/v1/messages,x-api-key,your-key,false,Claude 3
```

### Lokalny serwer
```csv
local-model,http://192.168.1.100:8080/generate,,,false,Lokalny model
```

## ğŸ“ Struktura Projek